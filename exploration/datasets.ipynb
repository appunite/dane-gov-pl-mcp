{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "base_url = 'https://api.dane.gov.pl/1.4'\n",
    "params = {\n",
    "    'page': 1,\n",
    "    'per_page': 100,\n",
    "    'sort': 'id'\n",
    "}\n",
    "\n",
    "all_datasets = []\n",
    "while True:\n",
    "    response = requests.get(base_url + '/datasets', params=params)\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            data = response.json()\n",
    "            datasets = data.get('data')\n",
    "            for dataset in datasets:\n",
    "                attributes = dataset.get('attributes', {})\n",
    "                all_datasets.append(\n",
    "                    {\n",
    "                        'id': dataset.get('id'),\n",
    "                        'title': attributes.get('title'),\n",
    "                        'formats': attributes.get('formats'),\n",
    "                        'license_name': attributes.get('license_name'),\n",
    "                        'type': dataset.get('type'),\n",
    "                        'categories': attributes.get('categories'),\n",
    "                        'category': attributes.get('category'),\n",
    "                    }\n",
    "                )\n",
    "            if 'next' in data.get('links'):\n",
    "                params['page'] += 1\n",
    "            else:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f'Error: {e}')\n",
    "            break\n",
    "    else:\n",
    "        print(f'Failed to fetch data {params}. Status code: {response.status_code}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3639\n",
      "{'page': 37, 'per_page': 100, 'sort': 'id'}\n",
      "{'id': '1', 'title': 'Dane liczbowe dot. kontroli prowadzonych przez WIIH w 2014 r.', 'formats': ['xlsx'], 'license_name': 'CC0 1.0', 'type': 'dataset'}\n"
     ]
    }
   ],
   "source": [
    "print(len(all_datasets))\n",
    "print(params)\n",
    "print(all_datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xlsx']: 329\n",
      "['pdf']: 91\n",
      "['xls']: 80\n",
      "['docx', 'html', 'json', 'pdf']: 2\n",
      "[]: 93\n",
      "['xls', 'xlsx']: 59\n",
      "['csv', 'zip']: 6\n",
      "['csv']: 484\n",
      "['html']: 241\n",
      "['csv', 'jsonld', 'pdf', 'xlsx']: 10\n",
      "['csv', 'xml']: 4\n",
      "['doc', 'html', 'xml']: 1\n",
      "['pdf', 'xlsx']: 26\n",
      "['csv', 'jsonld', 'xlsx']: 532\n",
      "['csv', 'jsonld']: 296\n",
      "['pdf', 'xls']: 9\n",
      "['html', 'rdf']: 5\n",
      "['zip']: 23\n",
      "['xml']: 284\n",
      "['html', 'xlsx']: 6\n",
      "['csv', 'doc', 'jsonld', 'pdf', 'xls']: 1\n",
      "['html', 'xml']: 51\n",
      "['pdf', 'zip']: 10\n",
      "['html', 'zip']: 7\n",
      "['doc']: 12\n",
      "['csv', 'pdf', 'xlsx', 'xml']: 1\n",
      "['csv', 'jsonld', 'xls']: 23\n",
      "['csv', 'pdf', 'xlsx']: 8\n",
      "['json', 'xml']: 25\n",
      "['csv', 'html', 'jsonld', 'xml']: 6\n",
      "['docx', 'pdf']: 5\n",
      "['csv', 'jsonld', 'xls', 'xlsx']: 45\n",
      "['csv', 'xlsx']: 140\n",
      "['html', 'xls']: 3\n",
      "['csv', 'txt']: 3\n",
      "['csv', 'jsonld', 'rar', 'xlsx']: 1\n",
      "['pdf', 'png']: 1\n",
      "['csv', 'docx', 'jsonld', 'pdf', 'xlsx']: 1\n",
      "['json']: 30\n",
      "['html', 'pdf', 'xls', 'zip']: 1\n",
      "['html', 'jsonld']: 1\n",
      "['7z', 'html', 'pdf', 'xls', 'xlsx']: 1\n",
      "['html', 'pdf']: 3\n",
      "['html', 'xls', 'xlsx']: 8\n",
      "['csv', 'jsonld', 'pdf', 'rtf', 'xls']: 1\n",
      "['csv', 'html', 'jsonld', 'xlsx', 'xml']: 2\n",
      "['csv', 'html', 'jsonld', 'zip']: 4\n",
      "['html', 'pdf', 'xlsx']: 1\n",
      "['geojson', 'xml']: 2\n",
      "['html', 'xls', 'xlsx', 'zip']: 1\n",
      "['7z', 'pdf']: 1\n",
      "['shp', 'zip']: 3\n",
      "['html', 'xls', 'xlsx', 'xml']: 1\n",
      "['7z', 'pdf', 'rtf', 'zip']: 1\n",
      "['csv', 'php', 'xml']: 19\n",
      "['csv', 'jsonld', 'zip']: 5\n",
      "['docx', 'pdf', 'xml']: 2\n",
      "['csv', 'txt', 'xls', 'xlsx']: 1\n",
      "['html', 'pdf', 'xml']: 3\n",
      "['csv', 'ods', 'xlsx']: 1\n",
      "['html', 'rar', 'zip']: 1\n",
      "['geojson', 'html', 'xml']: 1\n",
      "['pdf', 'xls', 'xlsx']: 4\n",
      "['html', 'json', 'pdf', 'xml']: 1\n",
      "['csv', 'html', 'jsonld', 'xlsx']: 5\n",
      "['csv', 'html', 'jsonld', 'xls', 'xlsx']: 4\n",
      "['csv', 'html', 'xls', 'xml', 'zip']: 1\n",
      "['csv', 'xls', 'xlsx']: 4\n",
      "['csv', 'jsonld', 'xls', 'xlsx', 'zip']: 1\n",
      "['csv', 'pdf']: 3\n",
      "['html', 'json']: 8\n",
      "['csv', 'jsonld', 'xlsx', 'xml']: 6\n",
      "['html', 'jpeg', 'xml']: 1\n",
      "['docx', 'xls', 'xlsx']: 1\n",
      "['csv', 'jsonld', 'xls', 'xml']: 4\n",
      "['html', 'xml', 'zip']: 1\n",
      "['xml', 'zip']: 6\n",
      "['json', 'pdf']: 22\n",
      "['ods', 'xlsx']: 1\n",
      "['doc', 'pdf', 'xlsx']: 1\n",
      "['csv', 'jsonld', 'php', 'xml']: 1\n",
      "['php', 'xml']: 1\n",
      "['doc', 'html']: 1\n",
      "['csv', 'jsonld', 'pdf', 'xls', 'xlsx']: 4\n",
      "['csv', 'docx', 'html', 'jsonld', 'pdf', 'xls', 'xlsx']: 1\n",
      "['7z', 'zip']: 3\n",
      "['doc', 'docx']: 2\n",
      "['xlsx', 'zip']: 3\n",
      "['csv', 'html']: 5\n",
      "['rar', 'zip']: 1\n",
      "['csv', 'jsonld', 'txt', 'xlsx']: 2\n",
      "['csv', 'jsonld', 'ods', 'xlsx']: 1\n",
      "['csv', 'xls']: 53\n",
      "['docx', 'html', 'pdf', 'xlsx']: 1\n",
      "['ods']: 9\n",
      "['docx']: 9\n",
      "['odt']: 1\n",
      "['csv', 'odt']: 1\n",
      "['csv', 'xlsx', 'xml']: 7\n",
      "['csv', 'html', 'json', 'xml']: 1\n",
      "['csv', 'jsonld', 'txt']: 4\n",
      "['json', 'zip']: 2\n",
      "['csv', 'html', 'xlsx']: 1\n",
      "['csv', 'doc', 'docx', 'jsonld', 'xlsx']: 1\n",
      "['html', 'xlsx', 'xml']: 1\n",
      "['csv', 'docx', 'zip']: 1\n",
      "['csv', 'jsonld', 'ods', 'pdf', 'xlsx']: 2\n",
      "['json', 'pdf', 'txt', 'zip']: 1\n",
      "['csv', 'txt', 'xlsx']: 1\n",
      "['csv', 'html', 'jsonld', 'xls', 'xml']: 1\n",
      "['csv', 'xlsx', 'zip']: 1\n",
      "['csv', 'docx', 'pdf']: 1\n",
      "['html', 'xlsx?=', 'xml']: 1\n",
      "['csv', 'html', 'jsonld', 'xls']: 2\n",
      "['docx', 'xlsx']: 3\n",
      "['csv', 'json']: 1\n",
      "['shp', 'xml', 'zip']: 1\n",
      "['html', 'json', 'xml']: 3\n",
      "['shp', 'xml']: 1\n",
      "['csv', 'json', 'jsonld', 'xlsx', 'xml']: 1\n",
      "['csv', 'docx', 'xml', 'zip']: 1\n",
      "['csv', 'jsonld', 'shp', 'xml']: 1\n",
      "['csv', 'geojson', 'jsonld', 'xlsx', 'xml']: 1\n",
      "['csv', 'jsonld', 'xml']: 2\n",
      "['csv', 'json', 'jsonld', 'xlsx']: 6\n",
      "['csv', 'docx', 'jsonld', 'xlsx']: 3\n",
      "['csv', 'html', 'xml']: 1\n",
      "['csv', 'html', 'jsonld']: 2\n",
      "['xls', 'xlsx', 'xml']: 1\n",
      "['doc', 'docx', 'pdf', 'xls', 'xlsx']: 1\n",
      "['jsonld']: 1\n",
      "['ods', 'odt', 'xlsx']: 1\n",
      "['html', 'tsv']: 1\n",
      "['csv', 'html', 'json', 'jsonld']: 1\n",
      "['csv', 'json', 'jsonld', 'xml']: 3\n",
      "['csv', 'json', 'xml']: 2\n",
      "['csv', 'jpeg', 'jsonld']: 1\n",
      "['jpeg', 'pdf']: 3\n",
      "['csv', 'json', 'jsonld']: 1\n",
      "['csv', 'png']: 2\n",
      "['7z', 'csv']: 1\n",
      "['csv', 'geotiff', 'jsonld', 'xlsx']: 1\n",
      "['png']: 1\n",
      "['json', 'xlsx']: 1\n",
      "['doc', 'pdf']: 1\n",
      "['shp']: 1\n",
      "['csv', 'jsonld', 'xlsx', 'zip']: 1\n",
      "['csv', 'shp']: 2\n",
      "['jpeg', 'xls']: 8\n",
      "['shp', 'wfs', 'wms']: 2\n",
      "['doc', 'ods', 'xls']: 1\n",
      "['geotiff', 'wcs', 'wms']: 2\n",
      "['fgb', 'shp', 'wfs', 'wms']: 1\n",
      "['tsv']: 7\n",
      "['csv', 'rdf']: 332\n",
      "['jpeg', 'ods', 'xlsx']: 1\n",
      "['docx', 'odt', 'pdf', 'xlsx']: 1\n",
      "['csv', 'jsonld', 'pdf', 'png', 'xlsx']: 1\n",
      "['jpeg', 'png']: 1\n",
      "['7z', 'csv', 'jpeg', 'pdf', 'zip']: 1\n",
      "['csv', 'geotiff', 'jsonld', 'pdf', 'xlsx']: 1\n",
      "['csv', 'geojson', 'json', 'xml']: 1\n",
      "['7z', 'jpeg', 'png']: 1\n",
      "['csv', 'jsonld', 'pdf']: 3\n",
      "['html', 'pdf', 'xls', 'xlsx']: 1\n",
      "['pdf', 'png', 'xlsx']: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "format_list_counter = defaultdict(int)\n",
    "for dataset in all_datasets:\n",
    "    formats = tuple(dataset['formats'])\n",
    "    format_list_counter[formats] += 1\n",
    "\n",
    "for format_list, count in format_list_counter.items():\n",
    "    print(f\"{list(format_list)}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'docx', 'tsv', 'doc', 'png', 'wfs', 'odt', 'html', 'jpeg', 'xlsx', 'xml', 'rdf', 'xlsx?=', 'csv', 'php', 'shp', 'ods', 'xls', 'rtf', 'json', 'zip', 'fgb', 'txt', 'geojson', 'geotiff', 'wms', 'jsonld', 'wcs', '7z', 'rar', 'pdf'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize a set to store unique formats\n",
    "unique_formats = set()\n",
    "\n",
    "# Iterate over each format set and add each format to the set\n",
    "for format_set in format_list_counter.keys():\n",
    "    unique_formats.update(format_set)\n",
    "\n",
    "# Print all unique formats\n",
    "print(unique_formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset counts by access class:\n",
      "Class 1: 1778 datasets\n",
      "Class 2: 1053 datasets\n",
      "Class 3: 541 datasets\n",
      "Class 4: 135 datasets\n",
      "Class 5: 39 datasets\n",
      "Class 6: 93 datasets\n",
      "\n",
      "Total datasets: 3639\n",
      "\n",
      "Percentages:\n",
      "Class 1: 48.9%\n",
      "Class 2: 28.9%\n",
      "Class 3: 14.9%\n",
      "Class 4: 3.7%\n",
      "Class 5: 1.1%\n",
      "Class 6: 2.6%\n"
     ]
    }
   ],
   "source": [
    "access_class_1 = ['json', 'geojson', 'jsonld', 'xml', 'html']\n",
    "access_class_2 = ['csv', 'tsv', 'txt', 'rdf']\n",
    "access_class_3 = ['xlsx', 'xls', 'ods', 'odt', 'rtf']\n",
    "access_class_4 = ['pdf', 'doc', 'docx', 'php']\n",
    "access_class_5 = ['jpeg', 'png', 'geotiff', 'wms', 'zip', '7z', 'rar', 'wcs', 'wfs', 'shp', 'fgb', 'xlsx?=']\n",
    "\n",
    "\n",
    "def classify_dataset(formats):\n",
    "    \"\"\"Classify dataset based on formats - lowest class number wins\"\"\"\n",
    "    if not formats:\n",
    "        return 6\n",
    "    \n",
    "    # Check each class in order (1 to 5)\n",
    "    if any(fmt in access_class_1 for fmt in formats):\n",
    "        return 1\n",
    "    elif any(fmt in access_class_2 for fmt in formats):\n",
    "        return 2\n",
    "    elif any(fmt in access_class_3 for fmt in formats):\n",
    "        return 3\n",
    "    elif any(fmt in access_class_4 for fmt in formats):\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "# Count datasets by class\n",
    "class_counts = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6:0}\n",
    "\n",
    "for dataset in all_datasets:\n",
    "    dataset_class = classify_dataset(dataset['formats'])\n",
    "    class_counts[dataset_class] += 1\n",
    "\n",
    "print(\"Dataset counts by access class:\")\n",
    "for class_num in sorted(class_counts.keys()):\n",
    "    print(f\"Class {class_num}: {class_counts[class_num]} datasets\")\n",
    "\n",
    "total = sum(class_counts.values())\n",
    "print(f\"\\nTotal datasets: {total}\")\n",
    "\n",
    "print(\"\\nPercentages:\")\n",
    "for class_num in sorted(class_counts.keys()):\n",
    "    percentage = (class_counts[class_num] / total) * 100\n",
    "    print(f\"Class {class_num}: {percentage:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "License name counts:\n",
      "'CC0 1.0': 1981\n",
      "'CC BY 4.0': 1593\n",
      "'CC BY-NC-SA 4.0': 36\n",
      "'CC BY-NC-ND 4.0': 16\n",
      "'CC BY-SA 4.0': 12\n",
      "'CC BY-NC 4.0': 1\n",
      "\n",
      "Total datasets: 3639\n",
      "Unique licenses: 6\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Count license names\n",
    "license_counter = defaultdict(int)\n",
    "\n",
    "for dataset in all_datasets:\n",
    "    license_name = dataset.get('license_name', 'Unknown')\n",
    "    license_counter[license_name] += 1\n",
    "\n",
    "# Print license counts\n",
    "print(\"License name counts:\")\n",
    "for license_name, count in sorted(license_counter.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"'{license_name}': {count}\")\n",
    "\n",
    "print(f\"\\nTotal datasets: {sum(license_counter.values())}\")\n",
    "print(f\"Unique licenses: {len(license_counter)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type counts:\n",
      "'dataset': 3639\n",
      "\n",
      "Total datasets: 3639\n",
      "Unique types: 1\n"
     ]
    }
   ],
   "source": [
    "type_counter = defaultdict(int)\n",
    "\n",
    "for dataset in all_datasets:\n",
    "    dataset_type = dataset.get('type', 'Unknown')\n",
    "    type_counter[dataset_type] += 1\n",
    "\n",
    "# Print type counts\n",
    "print(\"Dataset type counts:\")\n",
    "for dataset_type, count in sorted(type_counter.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"'{dataset_type}': {count}\")\n",
    "\n",
    "print(f\"\\nTotal datasets: {sum(type_counter.values())}\")\n",
    "print(f\"Unique types: {len(type_counter)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
